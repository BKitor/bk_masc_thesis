% Chapter 4 - Topology Awareness

\glsresetall % reset the glossary to expand acronyms again
\chapter[Topology]{Topology Awareness}\label{ch:TopologyAwareness}
\index{Topology Awareness}

% Topology Awareness

\begin{itemize}
    \item Microbenchmark Data
    \item Horovod, even though there's barely any improvement?
\end{itemize}

The first technique investigated to improve MPI collective communication performance is topology awareness.
The overarching idea is to accelerate computation by leveraging the knowledge of the underlying hardware.
Topology awareness is an often-used technique applied to many areas in both MPI and the greater HPC ecosystem.

This chapter builds on work by Mirsadeghi and Afsahi \cite{Mirsadeghi2016TopoAwareCollRR}, where the authors propose a method for applying topology awareness to allgather and broadcast.
Their work relies on the notion that collective algorithms have an implicit communication pattern, and that the ranks in a communicator can be reordered as to better fit the communication pattern to the host topology.
We start by extend their work to multiple new algorithms, in allreduce and broadcast.
Microbenchmark evaluation shows that we can see up to 80\% performance improvement under certain scenarios, and that we can outperformed the SCOTCH graph partitioning library \cite{Pellegrini2012SCOTCH}.

This chapter will start by outlining existing methods for applying topology awareness within MPI.
Next, we propose a method of accelerating MPI collectives and build an implementation targeting multiple MPI\_Allreduce and MPI\_Bcast algorithms.
Our work is evaluated in both CPU and GPU environments and can see up to 80\% improvement in certain scenarios.

\section{Motivation}
MPI provides a programming model so that processes on a distributed memory system can share data and work together.
MPI users are made to assume that any messages exchanged between any two ranks will have the same communication characteristics no matter what their ranks are. 
This abstraction provides a convenient programming environment allowing users to focus on building their application without worrying about the underlying hardware. 
Its simplicity also has the benefit of making portability easier, dissuading users from tying their application to a specific architecture.
But in reality, this assumption is false because modern computers are anything but simple. 
Compute nodes have expansive memory hierarchies spanning multiple caches, NUMA domains, and even GPU memory.
Furthermore, modern fabric interconnects have complex network topologies with variable performance depending on node location.
So, in reality, the hardware topology of the system has an outsized impact on message performance, which has a knock-on effect on overall application performance. 

MPI applications often have consistent and predictable data-transfer patterns, this means anyone rank will send and receive the same set of messages to and from the same set of peers on consecutive runs of the application.
Since data-transfer patterns are predictable, and the programming model doesn't bind processes to specific locations, this gives MPI implementations the flexibility to map ranks to processing elements to make the most optimal use of the underlying hardware.
This problem of mapping ranks to processing elements can be formalized as an instance of a graph-embedding problem. However, previous work has shown this to be an NP-Hard problem \cite{Hoefler2011GenericTopoMappingStrats}. 
Solving this problem at scale (on the order of millions of processes) is not feasible. Therefore heuristics and simplifications are often used instead.

To apply topology awareness to collectives, we can leverage how they are structured as a series of point-to-point communications.
The algorithmic implementation of a collective specifies a pattern of data exchanges, which can be interpreted as a communication graph.
MPI providers will often include multiple algorithms for different collectives with common patterns, including ring, recursive doubling, knomial-tree, etc...
This gives MPI implementations the flexibility to select a performant algorithm depending on the collective's parameters like message size and the number of processes.
This framework for algorithm selection neglects the host topology, but there is room to incorporate it.
The collective algorithm defines the pattern to disseminate data, but the value of the ranks in the graph often  does not matter (there are some algorithms where this does matter, like allgather, alltoall and non-commutative allreduce, but these can be accounted for).
So in this work, we evaluate the efficacy of mapping collective communication graphs to the underlying hardware topology on-the-fly during application runtime.


% Conseptualy, this problem can be treated as a graph mapping problem. 
% The MPI application is modeld as weighted graph $G=(V_G, w_G)$, where verticeis are processes and weights are the amount of communication between processes.
% The host topology is also models as a weighted graph $H=(V_h, w_H)$, where vertices are processing elements and weights represent the capacity of the interconnect between any two processing elements.
% % $G$ and $H$ are both fully connected graphs, and $|V_G| = |V_H|$.
% When running the application, the grpah $G$ is mapped to $H$ so that each rank in $V_G$ is overlayed on a processing element in $V_H$, and communication weights in $w_G$ are tied to a hardware link $w_H$.
% Lastly, a mathematical metric is defined to estimate the performance of the mapping.
% So the goal of topology-awareness is to find a mapping from $G$ to $H$ that minimized/maximized a defined metric.
% This problem, which is a subset of graph-embedding, is NP-hard, so finding optimal solutions for large scale instances of this problem is not feasable \cite{Hoefler2011GenericTopoMappingStrats}.
% Solutions used in practice often rely on heuristics to find near-optimal solutions in a reasonable amount of time.


\section{Background}
Topology awareness is a commonly used technique for accelerating MPI applications. 
Within MPI, there are many scenarios and methods where topology information can be applied to accelerate communication.
At the highest level, topology awareness can be applied to the application's entire communication graph \cite{Hoefler2011GenericTopoMappingStrats, Mirsadeghi2016PTRAM, Faraji2016TopoAwareGPUSelection, Mirsadeghi2016MAGC, Galvez2017AutoTopoMap}.
These strategies require profiling the entire application to build the communication graph.
This communication graph is then used in future runs of the application to devise a mapping for each job allocation.
The efficiency of a mapping is evaluated using metrics such as hop-bytes or congestion.
So to achieve the best application performance, mapping algorithms try to minimize/maximize their chosen metric.
There are multiple research fronts with this strategy, efforts have gone into optimizing the metrics, the mapping algorithm itself, and the types of systems mappings are supported for.

Hoefler and Snir \cite{Hoefler2011GenericTopoMappingStrats} propose a general process mapping tool targeting CPU clusters.
They evaluate three algorithms, a greedy algorithm based on vertecie weights, a recursive bisecting that makes minimum weighted edge-cuts, and a graph similarity mapping using the Reverse Cuthill McKee algorithm. 
They use these algorithms, along with a \textit{Threshold Accepting} optimization step, to minimize congestion and dilation on large-scale SMP clusters.

Mirsadeghi and Afsahi \cite{Mirsadeghi2016PTRAM} propose a system targeting large-scale Infiniband clusters.
Their system leverages the network topology plus Infiniband's static routing tables to further reduce congestion.
They propose a hybrid metric which is a linear combination of hop-bytes and three types of congestion statistics. 
The mapping, along with further refinements, are calculated using a parallel greedy algorithm.

Faraji et al. l \cite{Faraji2016TopoAwareGPUSelection} focus their efforts on building a system targeting intranode GPU communication.
While their system only works on a single node and relies on SCOTCH's \cite{Pellegrini2012SCOTCH} graph bisecting method to perform the mapping, Mirsadehi et al. \cite{Mirsadeghi2016MAGC} expand the work to a full cluster.
The complete system uses a 3-step process, first mapping ranks to nodes to minimize network communication, then ranks to core to optimize intranode communication, and lastly, the GPU-to-rank step for optimal GPU-to-GPU communications.

Existing systems struggle to manage collective communications.
The profiling stage is often built on top of the PMPI profiling interface, which can intercept MPI calls, but doesn't break collectives into their constituent point-to-point messages.
Galvez et al. \cite{Galvez2017AutoTopoMap} identify this problem and propose a profiler that groups types of communications into weighted classes.
Their system leverages a parallel algorithm that uses the communication classes, along with a set of weighted metrics, to calculate a near-ideal mapping.
While a step in the right direction, their solution still treats collective communications as a black box, focusing on the collective's communicator and not disassembling the collective into its constituent point-to-point messages.

In order to decompose collectives into point-to-point messages, Bosilica et al. \cite{Bosilica2017OnlineMonitoringMPI} implemented a monitoring layer in OpenMPI that is accessible through the MPI Tools interface.
This provides much more granular profiling for point-to-point messages, which allowed Jeannot and Sartori \cite{Jeannot2020ImprvMPICommMonitoring} to propose a rank reordering method for applications with iterative compute, but their solution is required to be implemented within the user's application. 
So while it is possible to apply topology awareness to all communication, including collectives, there is a large burden on application developers to implement it within their software.

One of the common shortcomings most of these systems have in common is the required application profiling.
The application needs to run at least once to build the communication graph, and this can be expensive for large-scale runs. 
An ideal solution would be able to build a graph for a moderate amount of processes and project a solution for a large-scale system, but no existing solution can perform this yet. 

The MPI standard does provide a few interfaces to allow application developers to inform the runtime of expected communication patterns.  
One of these solutions are virtual topologies. 
This is a structure attached to a communicator that tells the implementation how communications are likely to occur between ranks.
Mercer and Jeannot \cite{Mercer2011ImprvMPIWithRR} leverage the MPI\_Dist\_graph\_create endpoint to reorder processes on a graph topology.
Their solution centralizes the topology information and uses the TreeMatch algorithm \cite{Jeannot2010TreeMatch} to calculate a process reordering.
Gropp \cite{Gropp2019CartTopoMapping} proposes a method for reordering processes in a cartesian topology.
His method relies on MPI\_COMM\_TYPE\_SHARED and neglects network topology as well as memory hierarchy information.

The most common way to apply topology awareness within collectives is to use a hierarchical strategy.
This is done by splitting the communicator into intra-node and inter-node sub-communicators.
The intra-node communicator consists of processes that are all placed on the same node.
Each node selects a leader process which is a member of the inter-communicator.
The collective communication pattern is then implemented across the hierarchical structure, ensuring efficient hardware use between shared memory and network resources.

Lue et al. \cite{Luo2018ADAPT} propose a library for event-based collectives.
While the crux of their work is focused on minimizing synchronization dependencies within collectives, they do demonstrate how their work could easily be mapped to a hierarchical type algorithm.
Awan et al. \cite{Awan2016NCCLBcast} build a GPU-aware hierarchical bcast algorithm.
Their work leverages NCCL for optimal intra-node communication for large messages and relies on existing algorithms in MVAPICH2 for inter-node communication.

Subramoni et al. \cite{Subramoni2011SpeedAwareBcast} designed a broadcast algorithm that can take Infiniband topology and network speeds into account.
They gather network information using OFED management tools like ibnetdiscover and ibroute and use the information to build a reordered communicator using either a depth-first traversal or a breath-first traversal.
They only evaluate knomial and scatter-allgather collectives.

The work presented in this thesis is an extension of work by Mirsadeghi and Afsahi \cite{Mirsadeghi2016TopoAwareCollRR}.
Instead of building a communication graph to custom fit the host topology, this work leverages the existing algorithm but renumbers the ranks under the hood to better map the communication graph to the hardware.
Their work focuses on broadcast and allgather collectives, with remapping algorithms targeting ring, recursive doubling and binomial communication patterns.
We extend their work by looking at allreduce and the additional challenges the reduction operation adds to their method.
We also propose mapping algorithms for reduce-scatter-allgather, knomial and binary-tree communication patterns.


\section{Method}

\lstset{style = bklstc}
\lstset{label = lst:topo-generic-strategy}
\lstset{caption = General greedy heuristic for topology-aware rank reordering.}
\lstinputlisting[float=!htbp]{3_Chapters/4_Chapter_TopologyAwareness/Figures/TopoRR_strat.c}

When applying topology awareness to collectives there are two common stategies.
Either build a communication pattern that is designed to fit the hardware, or take an existing pattern and map it to better fit the hardware.
This work uses the latter strategy, we take the collective algorithm selected by the implementation and silently renumber the processes so as to better adapt it to the hardware.
When a collective is called, the MPI library selects an algorithm based on the message size and number of processes.
The communication pattern is implicit to the collective algorithm, so we define a heuristic tailored to specific algorithms that calculates how ranks should be renumbered.
To make the calculation efficient and scalable each proposed remapping heuristic leverages a greedy strategy, an outline of the general strategy is given in Listing \ref{lst:topo-generic-strategy}.
The basic structure starts with a reference rank, all process remappings will try to use hardware as close to the reference rank as possible.
Then the heuristic loops through the ranks, selecting the next rank to map based on the communication patern, updating the reference rank when required.

The mapping is enforced by creating a new communicator, each process calls MPI\_Comm\_split() and requests their new rank, and the specified algorithm is run on the resulting communicator.
Since communicator creartion is an expensive operation, this shadow communicator is cached so that it can be used again if the same communicator uses the same algorithm.

This structure is flexible, and alows us to evaluate multiple types of collectives.
In order to accelerate large message allreduce, we propose a reordering heuristic for reduce-scatter-allgather allreduce.
Furthurmore, since broadcast can be used as a component in allreudce, we also propose heuristics for two broadcast algorithms, knomial and binary tree broadcast.

\subsection{Reduce-Scatter-Allgather Allreduce}

\input{3_Chapters/4_Chapter_TopologyAwareness/Figures/Topo_graph_rsa}
\lstset{label = lst:topo-rsa}
\lstset{caption = Heuristic for rank reordering the reduce-scatter-allgather algorithm.}
\lstinputlisting[float=!htbp]{3_Chapters/4_Chapter_TopologyAwareness/Figures/Topo_RSA.c}

Reduce-scatter-allgather (RSA) allreduce, also known as Rabenseifner's algorithm, is a popular algorithm implemented in most MPI implementations, and even used in external collective libraries like UCC \cite{UCC}.
The algorithm starts with each processess performing a recursive-vector halving reduce-scatter, this distributs a segment of the fully reduced vector to each rank.
At this point, each rank need to gather the other reduced segments from the other ranks, this is acheived thorugh a recursive doubling allgather.
RSA is used for large message allreduce because it makes efficient use of system bandiwth.
For an allreduce with $p$ processes on $n$ bytes of data, each rank sends $2((p-1)/p)n\beta$ bytes of data, linear scaling with message size is ideal for large message collectives.
In terms of structure, since both phases rely on a recusive pattern data is only exchanged with ranks that are a power of 2 distance away.
The other important feature of RSA is that more data is exchanged with numericly closer ranks.
Figure \ref{fig:graph-rsa} demonstrates this phenomona with 8 processes.
The most data is exchanged with immediate neighbours, this accounts for the first stage of reduce-scatter and the stage of the allgather.

So while designing our heuristic, we want to map communicating pairs that are a power of two distance away, with a focus on small distances first.
With these goals in mind, we propose the heuristic in Listing \ref{lst:topo-rsa} to target the RSA algorithm.
This heuristics starts by mapping rank 0 (line 14), then walks to the power of 2 communication graph mapping processes that have not been mapped yet (lines 18-24). 
While looping throug all the ranks, the reference rank is updated every two mappings(lines 25-31), this ensures that communicating pairs that are distance 1 away are mapped as close as possible. 


\subsection{Binary Tree Broadcast}

\input{3_Chapters/4_Chapter_TopologyAwareness/Figures/Topo_graph_bintree}
\lstset{label = lst:topo-bintree}
\lstset{caption = Heuristic for rank reordering binary trees.}
\lstinputlisting[float=!htbp]{3_Chapters/4_Chapter_TopologyAwareness/Figures/Topo_BinTree.c}

Binary tree benifit from it's simplicity.
Ranks recieve 1 message, and forward it to 2 child ranks.
The tree structure provides logarithmic scaling to the number of messages sent, so binary trees are often used for smaller message sizes. 
A typical structure for a binary tree is provided in Figure \ref{fig:graph-bin-tree}.
For a rank $r$, the height in the tree can be calculated as $h_r = \lfloor log_2(r+1) \rfloor$, and ranks will send messages to $r + 2^{h_r}$ and $r + 2^{h_r + 1}$
This leads to a structure where processes furthur down the tree are sending to ranks furthur and furthur away.
Furthurmore, Binary trees are constructued slightly lopsided, nodes are added to the left side of the tree before the right side. 
This can lead to situations where one direction has slightly more nodes than the other, this should be accounted for when desiging the heuristic.

In order to ensure that rank's reside on the same node as their children, we propose a depth-first-traversal heuristic, with the code provided in Listing \ref{lst:topo-bintree}.
We employ a recusive function to traverse the tree in an efficient manor. 
We start by mapping the root of the tree (line 38) and passing it in as the reference rank to the recursive function.
The recursive function starts by calculating the reference rank's height and child processes (lines 13). 
The, depending on if the child processes are in the communicator, we bind them close to the reference rank and recuse with them as the new reference rank.
To account for a potentialy lopsided tree, the heuristics traverses the potentialy smaller side first by mapping the numericly greater child first, (lines 27-23).
We found that this does a more consistant job of mapping the tree to common system architectures.


\subsection{Knomial Broadcast}

\input{3_Chapters/4_Chapter_TopologyAwareness/Figures/Topo_graph_knomial}
\lstset{label = lst:topo-knomial}
\lstset{caption = Heuristic for rank reordering knomial trees.}
\lstinputlisting[float=!htbp]{3_Chapters/4_Chapter_TopologyAwareness/Figures/Topo_Knomial.c}

Knomial is a generalization of a binomial tree and it's structure can be defined inductively.
For a knomial tree $T_{k,h}$ of height $h$ and radix $k$, if $h=0$ then $T_{k,h}$ is a single node. For $h>0$, $T_{k,h}$ is build from $k$ coppies of $T_{k,h-1}$, where the root of the first copy is the parent node of the other $k-1$ coppies.
Figure \ref{fig:graph-knomial} provides a example of a knomial tree with radix 4 and 16 processes.
While any value of $k$ can be used, implementatinos commonly use either 2 (binomial tree) or 4. 
While the structue of the tree is heavily lopsided, in theory this provides the opertunity to overlap message transfers at lower layers of the tree with transfers higher in higher layers.
Due to the inductive definitions, high $k$ value trees will have a lot of leaf nodes, as each subtree will contain of $k-1$ subtrees with $h=0$.

In Listing \ref{lst:topo-knomial}, we propose another depth frist traversal algorithm, with a focus on mapping smaller subtrees first.
By focusing on subtrees we are trying to group bunches of leaf nodes on the same node as their parent.
Since this is a depth first traversal, we use another recurisve function to traverse the tree. 
Once again, we start by mapping the root of the tree (line 42) and passing it in as the reference rank of the recursive function.
In the recusive function, we immidiatly map the $k-1$ subtrees of height 0 (lines 14-17).
Then we use a while loop to calculate the values for subtrees that are furthur away (lines 18-34).
If the root of a subtree does exist in the communicator, we map it as close as possible to the reference rank (line 28), calculate it's depth (line 30), and recurse on it as the reference rank (line 30).

\subsection{Evaluation}

There are some caviats with collective rank reordering as not all collectives can support it seamlessly.
By default MPI\_Allreduce doesn't enfore communtativity, a user can still request an operation to be commutative in the order of processor ranks. 
In order to support commutativity, Allreduce algorithms needs to be carfuly designed to ensure operations are applied in the correct order, and renumbering processes breaks that careful design.
Therefore, this work does not support commutative operations.
Furthurmore, both broadcast heuristics assume rank 0 is the root which is not always true. 
So when rank 0 isn't the broadcast root, it needs to recive the data from the real root before it can start the broadcast on the shadow-communicator.
In retrospect, a smarter desing would have been to assign virtual ranks by shifting each rank according to the root's value, this would make the root 0.
But I last looked at the code for remaping a year ago and the performance difference provided by this step would be negligable, furthurmore OMB only calls bcast w/ root 0 and Horovod doesn't use bcast.

We leverages existing system topology detection tools to generate the host topology matrix.
Hwloc \cite{Broquedis2010hwloc} is a tool for gathering on intranode topology information, this includes NUMA domaains and cache hierarchies.
To extract the network topology, we started by collecting topology information using each clusters provided tools, ibnetdiscovee for Beluga's infiniband netowrk and opareport for Cedar's OmniPath fabric.
We then transformed both file into a common format and saved it to disk.
When creating a topology matrix each node is responsible for generating the row coresponding to it's rank, this is done by indexing to the topology file, and checking neighboring ranks with Hwloc, then an allgather is performed to gather the final results.
This method is not necicarly that scalable as the memory requirements are on the order of $O(n^2)$ with the number of processes.

We implemented our method within OpenMPI v4.0.5 \cite{gabriel2004OpenMPI}.
Building on top of OpenMPI let us leverage the existing collective implementations as well as the algorithm selection mechanism.
OpenMPI also has suport for Hwloc intrgrated within the runtime, making topology detection easier.

While OpenMPI does support CUDA memory transfers, the implementation of CUDA-based allreduce coppies the data to a temporary host buffer, performs a CPU-based allreudce, then coppies the data back up to the GPU.
While this does fufill the MPI specification, it neglects to make use of the available GPU hardware, both kernel reduction, as well as GPU to GPU NVLinks.
So we modified OpenMPI's RSA algorithm to make use of GPU hardware, this is also more in line with how modern collective libraries like NCCL and UCC implement allreduce \cite{UCC, NCCL}.

In order to compare our proposed heuristics against an established topology mapping tool, we also intragrated the SCOTCH graph embeding tool \cite{Pellegrini2012SCOTCH} into the rank reordering method.
SCOTCH uses a graph bisecting method to perform graph partitioning and embedding, and it has been used in preveous work to incorporate topology-awareness \cite{Mirsadeghi2016TopoAwareCollRR}.

We evaluated our work on two herogenous clusters, Beluga and Cedar, both provided by Compute Canada. 
Beluga is Infiniband based, structured as a 5:1 blocking fat-tree with static routing.  
The CPU nodes have dual socket Xeon Gold 6148 Skylake processors, and the GPU nodes use the same processors attached to 4 V100s fully connected with NVLink.
Cedar, on the other hand, is OmniPath based.
It also has a fat-tree topology configured, bus it configured with 2:1 blocking and has adadaptive routing.
Cedar's CPU allocation has dual socket 24-core Xeon Platinum 8260 Cascade Lake processors, while the GPU nodes have two 20-core Xeon Silver 4216 Cascade Lake processors hosting four v100s GPUs interconnected by NVLink.

We used OSU-Microbenchamrks v5.7 \cite{Bureddy2012OMB} to evaluate the performance of our proposed method. 
This tool performs 1000 loops over MPI\_Allreduce, measures the runtime of each function call, and outputs the average latency. 
It also provides the optinion to locate the data buffer in either CPU memory or GPU memory.

\input{3_Chapters/4_Chapter_TopologyAwareness/Figures/init_mapping}
The rank reordering strategy finds performance impovements by rearanging the process to core bindings, which implies that any performance improvements are dependant on the initial process to core bindings.
At job launch, processes are bound to a specified resource in a round-robin fashion.
Figure \ref{fig:init-mappings} provides an example outlining three initial mappings we evaluated.
The default inital mapping is by-package, this takes a node and fills it with processes alternating between packages until the node is full, it then repeats this on the next node untill all processes are bound.
By-core mapping places processes to consecutivly numbered cores filling up a node befor moving to the next, and by-node scatters processes accross nodes by cycling through nodes placing proecsses one at a time.

% \input{3_Chapters/4_Chapter_TopologyAwareness/Figures/ac_frac_imprv_small}

% \input{3_Chapters/4_Chapter_TopologyAwareness/Figures/bc_frac_imprv_small}

% \input{3_Chapters/4_Chapter_TopologyAwareness/Figures/dual_64_1024}

Microbenchmakrs

Horovod? Cosmoflow?